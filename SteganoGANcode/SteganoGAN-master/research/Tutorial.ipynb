{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before using this tutorial, ensure that the following are on your system:\n",
    "\n",
    "- <b>SteganoGAN is installed</b>. Install via pip or source code. \n",
    "- <b>Training and Validation Dataset are available </b>. Download via data/download.sh or retrieve your own.\n",
    "\n",
    "It is also suggested that you have the following:\n",
    "\n",
    "- <b>CUDA-enabled machine</b>. SteganoGAN takes very long to train without a GPU. Use AWS to have access to CUDA machines.\n",
    "\n",
    "\n",
    "Now, we retrieve each of the imports required by steganoGAN\n",
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numpy is used for a parameter input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steganogan import SteganoGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imports the SteganoGAN class which has the wrapper functions for SteganoGAN usage:\n",
    "\n",
    "- <b>Create a SteganoGAN architecture</b> \n",
    "- <b>Train a SteganoGAN architecture</b>\n",
    "- <b>Load a SteganoGAN model</b>\n",
    "- <b>Encode and decode operations for SteganoGAN models</b>\n",
    "\n",
    "We retrieve each of these functions later in the tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataLoader is used to do the following:\n",
    "\n",
    "- <b>Load images</b> from a selected database\n",
    "- <b>Specify hyperparameters</b> for database loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steganogan.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoders are the architectural models that are used to encode the messages inside the image. There are two types of encoders that can be imported:\n",
    "\n",
    "- <b>Basic Encoder</b>: This is memory-efficient but not as robust as the other model\n",
    "- <b>Dense Encoder</b>: This is a more robust model with a denser architecture\n",
    "\n",
    "Please review the SteganoGAN paper for images of the two architectures. A steganoGAN model can only use one of these encoders. You may select which one to use in your model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steganogan.encoders import BasicEncoder, DenseEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoders are the architectural models that are used to decode the messages inside the image. There are two types of decoders that can be imported:\n",
    "\n",
    "- <b>Basic Decoder</b>: This is memory-efficient but not as robust as the other model\n",
    "- <b>Dense Decoder</b>: This is a more robust model with a denser architecture\n",
    "\n",
    "Please review the SteganoGAN paper for images of the two architectures. A steganoGAN model can only use one of these dector. You may select which one to use in your model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steganogan.decoders import BasicDecoder, DenseDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Critic checks if an image is steganographic or not. At the current moment, we have the following Critic:\n",
    "\n",
    "- <b>Basic Critic</b>: This is a GAN discriminator that ensures images are well hid. \n",
    "\n",
    "SteganoGAN currently only uses a BasicCritic. This parameter will never be changed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steganogan.critics import BasicCritic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "\n",
    "In the next cell, we load in the data for our training and validation dataset. The training dataset is used to train the model while the validation dataset is used to ensure that the model is working correctly. There are several parameters that can you choose to tune.\n",
    "\n",
    "- <b>path:str</b> - This can be a relative path or an absolute path from the notebook file. \n",
    "\n",
    "- <b>limit:int</b> - The number of images you wish to use. If limit is set as np.inf, all the images in the directory will be used.\n",
    "\n",
    "- <b>shuffle:bool</b> - If true, your images will be randomly shuffled before being used for training.\n",
    "\n",
    "- <b>batch_size:int</b> - The number of images to use in a batch. A batch represents the number of images that are trained in a single training cycle (i.e. batch_size=10, means 10 images are sent through the network at once during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "np.inf=1000\n",
    "train = DataLoader('/data1/guoshi/PaperCode/SteganoGAN/SteganoGANcode/SteganoGAN-master/research/div2k/train/', limit=np.inf, shuffle=True, batch_size=4)\n",
    "validation = DataLoader('/data1/guoshi/PaperCode/SteganoGAN/SteganoGANcode/SteganoGAN-master/research/div2k/val/', limit=np.inf, shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting an Architecture\n",
    "\n",
    "Below we are deciding on the architecture that we want to use for SteganoGAN. There are several parameters that you can tune here to decide on the architecture. Let us go over them:\n",
    "\n",
    "- <b>data_depth:int</b> - Represents how many layers we want to represent the data with. Currently, data is representated as a N x data_depth x H x W. Usually, we set this to 1 since that suffices for our needs. For more robustness set this data depth to a higher number.\n",
    "- <b>encoder:EncoderInstance</b> - You can choose either a BasicEncoder or DenseEncoder.\n",
    "- <b>decoder:DecoderInstance</b> - You can choose either a DenseEncoder or DenseDecoder.\n",
    "- <b>critic:CritcInstance</b> - The only option is the BasicCritic\n",
    "- <b>hidden_size:int</b> - The number of channels we wish to use in the hidden layers of our architecture. You can tune this parameter. We chose 32 as we find relatively good models with these number of channels.\n",
    "- <b>cuda:bool</b> - If true and the machine is CUDA-enabled, CUDA will be used for training/execution\n",
    "- <b>verbose:bool</b> - If true, the system will print more output to console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device\n"
     ]
    }
   ],
   "source": [
    "# Create the SteganoGAN instance\n",
    "steganogan = SteganoGAN(1, BasicEncoder, BasicDecoder, BasicCritic, hidden_size=32, cuda=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Saving the Model\n",
    "\n",
    "\n",
    "Once the architecture has been decided and the training and validation data are we loaded, we can begin training. To train call the fit function with the following parameter options:\n",
    "\n",
    "- <b>train:DataLoaderInstance</b> - This is the training set that you loaded earlier.\n",
    "- <b>validation:DataLoaderInstance</b> - This is the validation that you loaded earlier.\n",
    "- <b>epochs:int</b> - This is the number of epochs you wish to train for. A larger number of epochs will lead to a more precise model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:53<00:00,  3.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:51<00:00,  3.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 25/25 [00:05<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:48<00:00,  4.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:47<00:00,  4.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 25/25 [00:05<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:46<00:00,  4.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:46<00:00,  4.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 25/25 [00:05<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:47<00:00,  4.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:45<00:00,  4.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 25/25 [00:05<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:46<00:00,  4.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [00:51<00:00,  3.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 25/25 [00:05<00:00,  4.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fit on the given data\n",
    "steganogan.fit(train, validation, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, we save the model to a .steg file. In this file, we save all the model weights and the architectures that these weights compose. Both the encoder and decoder are saved in the same file.\n",
    "\n",
    "The arguments taken are:\n",
    "- <b>path:str</b> - This is the path to save the model. Make sure that the directory exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the fitted model\n",
    "steganogan.save('demo.steg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Executing a Model\n",
    "\n",
    "The next command loads a previously generated model. It takes a couple of different parameters. \n",
    "\n",
    "- <b>architecture:str</b> - You can select either 'basic' or 'dense' architectures. \n",
    "- <b>path:str</b> - The path to a model that you have previously generated. \n",
    "- <b>cuda:bool</b> - If true and the machine is CUDA-enabled, CUDA will be used for training/execution\n",
    "- <b>verbose:bool</b> - If true, the system will print more output to console\n",
    "\n",
    "Note: <b>either architectures or path but not both must not be None</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data1/guoshi/anaconda3/envs/guo_gan/lib/python3.8/site-packages/steganogan/pretrained/demo1.steg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m steganogan \u001b[38;5;241m=\u001b[39m \u001b[43mSteganoGAN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchitecture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdemo1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/guo_gan/lib/python3.8/site-packages/steganogan/models.py:364\u001b[0m, in \u001b[0;36mSteganoGAN.load\u001b[0;34m(cls, architecture, path, cuda, verbose)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (architecture \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (architecture \u001b[38;5;129;01mand\u001b[39;00m path):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease provide either an architecture or a path to pretrained model.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 364\u001b[0m steganogan \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m steganogan\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n\u001b[1;32m    367\u001b[0m steganogan\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mupgrade_legacy()\n",
      "File \u001b[0;32m~/anaconda3/envs/guo_gan/lib/python3.8/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/guo_gan/lib/python3.8/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/guo_gan/lib/python3.8/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data1/guoshi/anaconda3/envs/guo_gan/lib/python3.8/site-packages/steganogan/pretrained/demo1.steg'"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "steganogan = SteganoGAN.load(architecture='demo', path=None, cuda=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function encodes an input image with a message and outputs a steganographic image. Note that since SteganoGAN only works on spatial-domains, the output image must be a PNG image.  \n",
    "\n",
    "The function takes the following arguments:\n",
    "- <b>input_image:str</b>: The path to the input image\n",
    "- <b>output_image:str</b>: The path to the output image\n",
    "- <b>secret_message:str</b>: The secret message you wish to embed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding completed.\n"
     ]
    }
   ],
   "source": [
    "# Encode a message in input.png\n",
    "steganogan.encode('input.png', 'output.png', 'secret and magic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function decode a steganographic image with a message and outputs a message. If no message is found, an error will be thrown by the function. Since steganoGAN encoders and decoders come in pairs, you <b>must</b> use the decoder that was trained with its corresponding encoder. \n",
    "\n",
    "The function takes the following arguments:\n",
    "- <b>stego_image:str</b>: The path to the steganographic image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find message.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Decode the message from output.png\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msteganogan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/guo_gan/lib/python3.8/site-packages/steganogan/models.py:334\u001b[0m, in \u001b[0;36mSteganoGAN.decode\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# choose most common message\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(candidates) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    336\u001b[0m candidate, count \u001b[38;5;241m=\u001b[39m candidates\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m candidate\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find message."
     ]
    }
   ],
   "source": [
    "# Decode the message from output.png\n",
    "steganogan.decode('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:guo_gan]",
   "language": "python",
   "name": "conda-env-guo_gan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
